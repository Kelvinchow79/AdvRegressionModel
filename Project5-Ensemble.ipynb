{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, HistGradientBoostingRegressor, VotingRegressor, StackingRegressor, ExtraTreesRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 173)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('train_full.csv',index_col=[0])\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>...</th>\n",
       "      <th>Heating_GasW</th>\n",
       "      <th>Heating_Grav</th>\n",
       "      <th>Heating_OthW</th>\n",
       "      <th>Heating_Wall</th>\n",
       "      <th>GarageType_2Types</th>\n",
       "      <th>GarageType_Attchd</th>\n",
       "      <th>GarageType_Basment</th>\n",
       "      <th>GarageType_BuiltIn</th>\n",
       "      <th>GarageType_CarPort</th>\n",
       "      <th>GarageType_Detchd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  LotShape  LandContour  LandSlope  \\\n",
       "0          10         65.0     8450         3            3          0   \n",
       "1           5         80.0     9600         3            3          0   \n",
       "2          10         68.0    11250         0            3          0   \n",
       "3          11         60.0     9550         0            3          0   \n",
       "4          10         84.0    14260         0            3          0   \n",
       "\n",
       "   BldgType  HouseStyle  OverallQual  OverallCond  ...  Heating_GasW  \\\n",
       "0         0           5            7            5  ...             0   \n",
       "1         0           2            6            8  ...             0   \n",
       "2         0           5            7            5  ...             0   \n",
       "3         0           5            7            5  ...             0   \n",
       "4         0           5            8            5  ...             0   \n",
       "\n",
       "   Heating_Grav  Heating_OthW  Heating_Wall  GarageType_2Types  \\\n",
       "0             0             0             0                  0   \n",
       "1             0             0             0                  0   \n",
       "2             0             0             0                  0   \n",
       "3             0             0             0                  0   \n",
       "4             0             0             0                  0   \n",
       "\n",
       "   GarageType_Attchd  GarageType_Basment  GarageType_BuiltIn  \\\n",
       "0                  1                   0                   0   \n",
       "1                  1                   0                   0   \n",
       "2                  1                   0                   0   \n",
       "3                  0                   0                   0   \n",
       "4                  1                   0                   0   \n",
       "\n",
       "   GarageType_CarPort  GarageType_Detchd  \n",
       "0                   0                  0  \n",
       "1                   0                  0  \n",
       "2                   0                  0  \n",
       "3                   0                  1  \n",
       "4                   0                  0  \n",
       "\n",
       "[5 rows x 173 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train['SalePrice']\n",
    "x=train.drop(['SalePrice'],axis=1)\n",
    "X_train, X_valid, y_train, y_valid=train_test_split(x,y,random_state=73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, x.values, y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 0.1135 (0.0060)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet score: 0.1135 (0.0061)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\CHOWKELVIN\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:188: LinAlgWarning: Ill-conditioned matrix (rcond=2.73212e-19): result may not be accurate.\n",
      "  overwrite_a=False)\n",
      "D:\\Users\\CHOWKELVIN\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:188: LinAlgWarning: Ill-conditioned matrix (rcond=6.31053e-19): result may not be accurate.\n",
      "  overwrite_a=False)\n",
      "D:\\Users\\CHOWKELVIN\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:188: LinAlgWarning: Ill-conditioned matrix (rcond=2.85448e-19): result may not be accurate.\n",
      "  overwrite_a=False)\n",
      "D:\\Users\\CHOWKELVIN\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:188: LinAlgWarning: Ill-conditioned matrix (rcond=2.38671e-19): result may not be accurate.\n",
      "  overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Ridge score: 1.6932 (1.0302)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\CHOWKELVIN\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:188: LinAlgWarning: Ill-conditioned matrix (rcond=2.45003e-19): result may not be accurate.\n",
      "  overwrite_a=False)\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(KRR)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_log_error(y_valid, y_preds):\n",
    "    \"\"\"Calculate root mean squared error of log(y_true) and log(y_pred)\"\"\"\n",
    "    if len(y_preds)!=len(y_valid): return 'error_mismatch'\n",
    "    y_preds_new = [math.log(x) for x in y_preds]\n",
    "    y_valid_new = [math.log(x) for x in y_valid]\n",
    "    return mean_squared_error(y_valid_new, y_preds_new, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.1359466044233098\n"
     ]
    }
   ],
   "source": [
    "RF_f=RandomForestRegressor(bootstrap=False, max_depth=60, max_features='sqrt',\n",
    "                      min_samples_split=4, n_estimators=1700)\n",
    "RF_f.fit(X_train,y_train)\n",
    "y_pred_RF_f=RF_f.predict(X_valid)\n",
    "print('RMSLE:', root_mean_squared_log_error(y_valid, y_pred_RF_f))\n",
    "#0.141125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.132730055900028\n"
     ]
    }
   ],
   "source": [
    "XT=ExtraTreesRegressor(n_estimators=1000,random_state=73)\n",
    "XT.fit(X_train,y_train)\n",
    "y_pred_XT=XT.predict(X_valid)\n",
    "print('RMSLE:', root_mean_squared_log_error(y_valid, y_pred_XT))\n",
    "#0.140768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.1840811376048676\n"
     ]
    }
   ],
   "source": [
    "Ada_f=AdaBoostRegressor(learning_rate=0.03, loss='exponential', n_estimators=2300,\n",
    "                  random_state=73)\n",
    "Ada_f.fit(X_train,y_train)\n",
    "y_pred_Ada_f=Ada_f.predict(X_valid)\n",
    "print('RMSLE:', root_mean_squared_log_error(y_valid, y_pred_Ada_f))\n",
    "#0.189845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.1301974304192531\n"
     ]
    }
   ],
   "source": [
    "GB_f=GradientBoostingRegressor(max_depth=10, max_features='sqrt',\n",
    "                          min_samples_split=12, n_estimators=1500)\n",
    "GB_f.fit(X_train,y_train)\n",
    "y_pred_GB_f=GB_f.predict(X_valid)\n",
    "print('RMSLE:', root_mean_squared_log_error(y_valid, y_pred_GB_f))\n",
    "#0.136772"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.12826726693601748\n"
     ]
    }
   ],
   "source": [
    "HGB_f=HistGradientBoostingRegressor(learning_rate=0.02,\n",
    "                              loss='least_absolute_deviation', max_depth=40,\n",
    "                              max_iter=750, min_samples_leaf=2,\n",
    "                              random_state=73)\n",
    "HGB_f.fit(X_train,y_train)\n",
    "y_pred_HGB_f=HGB_f.predict(X_valid)\n",
    "print('RMSLE:', root_mean_squared_log_error(y_valid, y_pred_HGB_f))\n",
    "#0.132428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.12196873766102913\n"
     ]
    }
   ],
   "source": [
    "XGB_f=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.6, gamma=0.5, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.05, max_delta_step=0, max_depth=4,\n",
    "             min_child_weight=1, monotone_constraints='()',\n",
    "             n_estimators=1200, n_jobs=0, num_parallel_tree=1, random_state=73,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "XGB_f.fit(X_train,y_train)\n",
    "y_pred_XGB_f=XGB_f.predict(X_valid)\n",
    "print('RMSLE:', root_mean_squared_log_error(y_valid, y_pred_XGB_f))\n",
    "#0.120656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "RMSLE: 0.12304024055396307\n"
     ]
    }
   ],
   "source": [
    "LGBg_f=LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "LGBg_f.fit(X_train,y_train)\n",
    "y_pred_LGBg_f=LGBg_f.predict(X_valid)\n",
    "print('RMSLE:', root_mean_squared_log_error(y_valid, y_pred_LGBg_f))\n",
    "#0.123494"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "RMSLE: 0.12016821115742808\n"
     ]
    }
   ],
   "source": [
    "Vote=VotingRegressor([('gb',GB_f),('hgb',HGB_f),('xgb',XGB_f),('lgb',LGBg_f)])\n",
    "Vote.fit(X_train,y_train)\n",
    "y_pred_Vote=Vote.predict(X_valid)\n",
    "print('RMSLE:', root_mean_squared_log_error(y_valid, y_pred_Vote))\n",
    "#0.122400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "RMSLE: 0.13084256101940536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "estimators=[('gb',GB_f),('hgb',HGB_f),('xgb',XGB_f),('lgb',LGBg_f)]\n",
    "Stack=StackingRegressor(estimators=estimators,final_estimator=RandomForestRegressor(n_estimators=800,random_state=42))\n",
    "Stack.fit(X_train,y_train)\n",
    "y_pred_Stack=Stack.predict(X_valid)\n",
    "print('RMSLE:', root_mean_squared_log_error(y_valid, y_pred_Stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
